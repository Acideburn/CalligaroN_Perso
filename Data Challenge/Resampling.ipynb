{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"valeo_xtrain.csv\",header=None,skiprows=[0])\n",
    "y_train = pd.read_csv(\"valeo_ytrain.csv\").values.ravel()\n",
    "X_test = pd.read_csv(\"valeo_xtest.csv\",header=None,skiprows=[0])\n",
    "X_train.shape,y_train.shape,X_test.shape\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.7</td>\n",
       "      <td>3.76</td>\n",
       "      <td>49.1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>111.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.52</td>\n",
       "      <td>122.23</td>\n",
       "      <td>20.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>34.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>126.96</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.2</td>\n",
       "      <td>3.77</td>\n",
       "      <td>50.3</td>\n",
       "      <td>3.76</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.38</td>\n",
       "      <td>163.78</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.55</td>\n",
       "      <td>38.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>133.88</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.7</td>\n",
       "      <td>3.78</td>\n",
       "      <td>40.4</td>\n",
       "      <td>3.78</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.09</td>\n",
       "      <td>207.73</td>\n",
       "      <td>26.39</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>135.28</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.9</td>\n",
       "      <td>3.77</td>\n",
       "      <td>34.9</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.45</td>\n",
       "      <td>177.31</td>\n",
       "      <td>25.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.06</td>\n",
       "      <td>116.51</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.75</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.17</td>\n",
       "      <td>174.73</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.42</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.12</td>\n",
       "      <td>140.92</td>\n",
       "      <td>11.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27581</th>\n",
       "      <td>32.9</td>\n",
       "      <td>3.81</td>\n",
       "      <td>39.7</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116.56</td>\n",
       "      <td>201.69</td>\n",
       "      <td>64.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>18.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>122.47</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27582</th>\n",
       "      <td>35.9</td>\n",
       "      <td>3.81</td>\n",
       "      <td>36.5</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.61</td>\n",
       "      <td>196.75</td>\n",
       "      <td>34.91</td>\n",
       "      <td>0.23</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.14</td>\n",
       "      <td>122.30</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27583</th>\n",
       "      <td>42.9</td>\n",
       "      <td>3.78</td>\n",
       "      <td>44.3</td>\n",
       "      <td>3.77</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.33</td>\n",
       "      <td>212.44</td>\n",
       "      <td>30.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>134.88</td>\n",
       "      <td>11.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27584</th>\n",
       "      <td>44.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>38.6</td>\n",
       "      <td>3.80</td>\n",
       "      <td>700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.21</td>\n",
       "      <td>135.55</td>\n",
       "      <td>40.67</td>\n",
       "      <td>0.41</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.23</td>\n",
       "      <td>115.81</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27585</th>\n",
       "      <td>46.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>32.2</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.58</td>\n",
       "      <td>205.01</td>\n",
       "      <td>25.57</td>\n",
       "      <td>0.23</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>117.45</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27586 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3       4    5    6    7      8    9  ...      18  \\\n",
       "0      35.7  3.76  49.1  3.78   300.0  1.0  1.0  2.0  111.7  8.0  ...   71.52   \n",
       "1      47.2  3.77  50.3  3.76    30.0  1.0  1.0  2.0  106.0  8.0  ...   67.38   \n",
       "2      52.7  3.78  40.4  3.78   300.0  1.0  1.0  2.0  103.4  8.0  ...   89.09   \n",
       "3      34.9  3.77  34.9  3.78  1000.0  2.0  1.0  1.0  146.0  7.0  ...   93.45   \n",
       "4      50.0  3.77  41.9  3.75   400.0  1.0  1.0  2.0  115.8  8.0  ...   85.17   \n",
       "...     ...   ...   ...   ...     ...  ...  ...  ...    ...  ...  ...     ...   \n",
       "27581  32.9  3.81  39.7  3.77  1000.0  2.0  1.0  1.0  129.4  7.0  ...  116.56   \n",
       "27582  35.9  3.81  36.5  3.79  1300.0  2.0  1.0  1.0  151.8  7.0  ...  112.61   \n",
       "27583  42.9  3.78  44.3  3.77   300.0  1.0  1.0  2.0   89.5  8.0  ...   95.33   \n",
       "27584  44.3  3.75  38.6  3.80   700.0  2.0  1.0  1.0  140.5  7.0  ...   65.21   \n",
       "27585  46.0  3.75  32.2  3.79  1300.0  2.0  1.0  1.0  147.7  7.0  ...   86.58   \n",
       "\n",
       "           19     20    21    22   23     24      25     26  target  \n",
       "0      122.23  20.57  0.55  34.7  2.0   9.54  126.96  11.97       0  \n",
       "1      163.78  18.73  0.55  38.7  2.0   9.54  133.88  11.97       0  \n",
       "2      207.73  26.39  0.55  30.2  2.0   9.66  135.28  11.97       0  \n",
       "3      177.31  25.73  0.59  17.6  1.0  12.06  116.51  11.97       0  \n",
       "4      174.73  21.50  0.42  52.0  1.0  12.12  140.92  11.98       0  \n",
       "...       ...    ...   ...   ...  ...    ...     ...    ...     ...  \n",
       "27581  201.69  64.99  0.60  18.5  1.0  12.21  122.47  11.97       0  \n",
       "27582  196.75  34.91  0.23  14.6  1.0  12.14  122.30  11.97       0  \n",
       "27583  212.44  30.40  0.55  29.0  2.0   9.61  134.88  11.98       0  \n",
       "27584  135.55  40.67  0.41  13.8  1.0  12.23  115.81  11.97       0  \n",
       "27585  205.01  25.57  0.23  11.7  1.0  12.32  117.45  11.97       0  \n",
       "\n",
       "[27586 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['target'] = y_train\n",
    "df = X_train\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26893, 28), (693, 28))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.target==0]\n",
    "df_minority = df[df.target==1]\n",
    "df_majority.shape,df_minority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26893, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=26893,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26893\n",
       "0    26893\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_upsampled.target\n",
    "X = df_upsampled.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf_1 = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "pred_y_1 = clf_1.predict(X)\n",
    "print( np.unique( pred_y_1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7009816680920685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print( accuracy_score(y, pred_y_1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807586165722265"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(criterion='mse', learning_rate=0.01, loss='deviance', max_depth=3, max_features='sqrt', n_estimators=1000)\n",
    "clf_dec_fct = cross_val_predict(clf, X, y, cv=3, method='decision_function')\n",
    "roc_auc_score(y, clf_dec_fct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803532025245142"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
