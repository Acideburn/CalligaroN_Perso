{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "- Extraction d'informations d'un site web.\n",
    "- A utiliser en l'absence de données ouvertes ou d'API.\n",
    "- Technique fragile car le site web peut changer du jour au lendemain.\n",
    "- Problématique juridique...\n",
    "\n",
    "**Avec requests**\n",
    "\n",
    "Doc :\n",
    "- requests : https://requests.readthedocs.io/en/master/\n",
    "\n",
    "Installation :\n",
    "- *pip install requests* ou *conda install -c anaconda requests*\n",
    "\n",
    "Exemple de site : https://www.beerwulf.com/fr-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://www.beerwulf.com/fr-fr')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str en précisant un encodage\n",
    "content = r.content.decode('utf-8')\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essai avec des regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle d'un prix avec une regex\n",
    "# extraction de tous les caractères différents de <\n",
    "# compris entre <span class=\"price\"> et </span>\n",
    "rx = re.compile('<span class=\"price\">([^<]+)</span>')\n",
    "match = rx.search(content)  # équivalent à match = re.search('<span class=\"price\">([^<]+)</span>', content)\n",
    "type(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction de niveau 0\n",
    "match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction de niveau 1\n",
    "match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle de tous les prix avec une regex\n",
    "for match in rx.finditer(content):\n",
    "    print(match.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La technique est très fragile car elle s'appuie sur la syntaxe HTML exacte et non sur la sémantique..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle de tous les prix avec une regex\n",
    "rx = re.compile('<span class=\"price from-price\">([^<]+)</span>')\n",
    "for match in rx.finditer(content):\n",
    "    print(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle de tous les prix avec une regex\n",
    "# ( from-price)? est une expression de capture\n",
    "# possibilité d'utiliser (?: from-price)? qui n'est pas une expression de capture\n",
    "rx = re.compile('<span class=\"price( from-price)?\">([^<]+)</span>')\n",
    "for match in rx.finditer(content):\n",
    "    print(match.group(1), match.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avec pandas.read_html()** recherche des tableaux dans les pages HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "\n",
    "Tableau page wikipédia: https://fr.wikipedia.org/wiki/Liste_des_pays_par_PIB_nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping d'une page HTML\n",
    "var = pd.read_html(\"https://fr.wikipedia.org/wiki/Liste_des_pays_par_PIB_nominal\")\n",
    "[df.shape for df in var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès au n° 2\n",
    "df = var[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès à des valeurs\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = columns du DataFrame\n",
    "df.iloc[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès à des valeurs\n",
    "df.iloc[[0, 1, 2, 76, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès à une valeur\n",
    "df.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher le code hexa \\xa0 : https://www.codetable.net/hex/a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aide sur read_html()\n",
    "# pd.read_html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion automatique du séparateur des milliers\n",
    "var = pd.read_html(\"https://fr.wikipedia.org/wiki/Liste_des_pays_par_PIB_nominal\",\n",
    "                    thousands='\\xa0',\n",
    "                    decimal=',')\n",
    "df = var[1]\n",
    "df.iloc[[0, 1, 2, 76, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reste à faire\n",
    "df.loc[df['Pays ou territoire'].str.contains(\"[^A-Za-zÀ-ÿ0-9 \\-']\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4**\n",
    "\n",
    "Extraire les noms des pays sans les annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avec beautifulsoup** parsing HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc :\n",
    "- beautifulsoup : https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "Installation :\n",
    "- *pip install beautifulsoup4* ou *conda install -c anaconda beautifulsoup4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple basique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <style>\n",
    "        h1 { font-size: 50px; }\n",
    "        body { font-family: Verdana; }\n",
    "        li { color: red; }\n",
    "        ul ul li { color: green; }\n",
    "        .highlighted { font-weight: bold; }\n",
    "        .italic { font-style: italic; }\n",
    "        .highlighted.italic { }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Mon titre</h1>\n",
    "        <p class=\"highlighted\">\n",
    "            Some text with a<br>\n",
    "            <a href=\"https://google.com\">link to google</a>\n",
    "            <img src=\"https://picsum.photos/200/300\">\n",
    "        </p>\n",
    "        <p>Some list:</p>\n",
    "        <ul>\n",
    "            <li>some item</li>\n",
    "            <li class=\"highlighted italic\">some item</li>\n",
    "            <li class=\"italic\">some item</li>\n",
    "            <ul>\n",
    "                <li>some other item 1</li>\n",
    "                <li>some other item 2</li>\n",
    "            </ul>\n",
    "            <li>some item</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tester sur : https://html.house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4\n",
    "soup = BeautifulSoup(html)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find h1\n",
    "titre = soup.find('h1')\n",
    "titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(titre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name\n",
    "titre.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text\n",
    "titre.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a\n",
    "link = soup.find('a')\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prochain tag\n",
    "link.find_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrs\n",
    "link.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text\n",
    "link.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find p\n",
    "paragraph = soup.find('p')\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find img in paragraph\n",
    "paragraph.find('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all\n",
    "soup.find_all('li', {'class': \"italic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idem avec un sélecteur css:\n",
    "soup.select('li.italic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les li de 2e niveau qui sont dans un ul lui-même dans un ul\n",
    "soup.find('ul').find('ul').find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idem avec un sélecteur css:\n",
    "soup.select('ul ul li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès au premier li\n",
    "li = soup.select('ul ul li')[0]\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prochain tag identique\n",
    "li.find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent\n",
    "li.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents\n",
    "li.parent.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# que les tags\n",
    "li.parent.find_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple 1**\n",
    "\n",
    "Le Bon Coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# premier essai avec leboncoin\n",
    "\n",
    "r = requests.get('https://www.leboncoin.fr/annonces/offres/ile_de_france/')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes erreurs du protocole HTTP : https://developer.mozilla.org/fr/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contenu\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en str\n",
    "print(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancement du script `server.py` lancé dans un terminal avec la commande :\n",
    "<code>python server.py --bind 127.0.0.1</code> sur Windows ou <code>python server.py --bind 0.0.0.0</code> sur MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat server.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec run de server.py\n",
    "r = requests.get('http://127.0.0.1:8000')  # http://0.0.0.0:8000\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec run de server.py\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec run de server.py\n",
    "from IPython.display import IFrame\n",
    "IFrame('http://127.0.0.1:8000', width=800, height=200)  # http://0.0.0.0:8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers\n",
    "headers = {\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0',\n",
    "'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'Accept-Language': 'fr,fr-FR;q=0.8,en-US;q=0.5,en;q=0.3',\n",
    "'Accept-Encoding': 'gzip, deflate',\n",
    "}\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd essai avec leboncoin\n",
    "r = requests.get('https://www.leboncoin.fr/annonces/offres/ile_de_france/',\n",
    "                 headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "soup = BeautifulSoup(r.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple 2**\n",
    "\n",
    "Craig List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essai avec craigslist\n",
    "r = requests.get('https://paris.craigslist.org/d/locations-de-vacances/search/vac')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "soup = BeautifulSoup(r.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise 2 méthodes :\n",
    "    \n",
    "- find(tag, attrs) : trouve le premier tag avec les attributs spécifiés\n",
    "- findAll(tag, attrs) : trouve tous les tags avec les attributs spécifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration du HTML\n",
    "# tag li avec class=\"result-row\"\n",
    "\n",
    "li_tag = soup.find('li', attrs={'class': 'result-row'})\n",
    "print(li_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(li_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La technique consiste par exemple à alimenter une liste de dictionnaires avec les valeurs trouvées pour chaque item et ensuite à le transformer en DataFrame :\n",
    "- soit en utilisant tag.attrs['attr'] pour collecter la valeur attr du tag <tag attr=value>\n",
    "- soit en utilisant tag.text pour collecter la valeur <tag>text</tag>\n",
    "- éventuellement en recherchant dans un nouveau tag à l'intérieur d'un tag donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collecte des informations\n",
    "# \"data-pid\"\n",
    "# \"time\"\n",
    "# \"title\"\n",
    "# \"price\"\n",
    "# \"housing\"\n",
    "# \"hood\"\n",
    "# \"data-ids\" (images)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for li_tag in soup.findAll('li', attrs={'class': 'result-row'}):\n",
    "    row = {}\n",
    "    row['data-pid'] = li_tag.attrs['data-pid']\n",
    "    # row['time'] = \n",
    "    # à compléter\n",
    "    rows.append(row)\n",
    "    \n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5**\n",
    "\n",
    "Compléter le DataFrame (sauf images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecte des photos\n",
    "# traitement des \"data-ids\"\n",
    "# séparation des formats et des noms de fichier\n",
    "# from javascript\n",
    "imageConfig = {\"1\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]},\n",
    "               \"4\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]},\n",
    "               \"0\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\"]},\n",
    "               \"3\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]},\n",
    "               \"2\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]}};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des photos\n",
    "from urllib import request\n",
    "from shutil import copyfileobj\n",
    "\n",
    "# data-ids\n",
    "img = '00d0d_3QrOcJHTZgj'\n",
    "size = '300x300'\n",
    "filename = '{}_{}.jpg'.format(img, size)\n",
    "url = 'https://images.craigslist.org/{}'.format(filename)\n",
    "\n",
    "# get the file from the web and save it locally\n",
    "with request.urlopen(url) as response, open(filename, 'wb') as out_file:\n",
    "    copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inconvénients du web scraping:\n",
    "- plutôt lent (car on parse potentiellement beaucoup de HTML inutile)\n",
    "- ne donne pas les résultats attendus si une partie du contenu est intégré dynamiquement à la page via javascript\n",
    "- un changement dans l'architecture du html ou du css (e.g: refonte du design du site) oblige à réécrire le programme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
