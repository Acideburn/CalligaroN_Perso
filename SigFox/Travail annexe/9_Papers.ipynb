{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ce jupyter s'appuie sur un paper :\n",
    "https://hal.telecom-paris.fr/hal-02367908/document\n",
    "## Il a été réalisé en collaboration avec Frederic Haykal \n",
    "donc une partie du code sera commune à nos deux rendus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idée maitresse de la solution :\n",
    "Nous allons produire un modèle par base.\\\n",
    "Ce modèle va apprendre à produire la distance entre la base et les messages reçus par cette base en s'appuyant sur le rssi.\\\n",
    "Le modèle va modéliser les perturbations terrain afin de pouvoir prédire une distance avec un rssi non fiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explication de l'idée\n",
    "Cas du GPS : le rssi donne la puissance recu du signal. ainsi avec cet valeur on peut définir la distance parcouru par le signal.\\\n",
    "Notre cas : Mais par construction dans notre cas ce rssi est perturbé par autre chose que la distance (le terrain). Nous utiliserons donc du Machine Learning pour apprendre ces perturbations et arriver a calculer cette distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### de plus\n",
    "On remarque que si l'on met les distances au lieu des 1 dans la df_feature on a de très bon résultat.\\\n",
    "Notre objectif sera donc de créer cette matrice dans le jeu de test en s'appuyant sur un modèle appris sur le train.\n",
    "\n",
    "Un dernier model prédira la position du message en s'appuyant sur cette nouvelle matrice.\\\n",
    "NB : nous rajouterons également les barycentres venant des autres jupyter pour encore augmenter la précision.\n",
    "\n",
    "Comme on peut le voir à la fin, malgré un overfit non négligeable les résultats sont prometteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IotTools import *\n",
    "#from IpyTools import *\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pickle\n",
    "from vincenty import vincenty\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mess_train = pd.read_csv('mess_train_list.csv')\n",
    "df_mess_test = pd.read_csv('mess_test_list.csv')\n",
    "pos_train = pd.read_csv('pos_train_list.csv')\n",
    "listOfBs = np.union1d(df_mess_train.bsid.unique(),df_mess_test.bsid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(listOfBs)\n",
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On corrige les bases outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons 27 bases outliers\n",
      "Base 9949 non vu\n",
      "il reste 0 base avec lat >60\n"
     ]
    }
   ],
   "source": [
    "X_train= Correct_Bases (df_mess_train)\n",
    "X_train[X_train.bs_lat>64].shape[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons 23 bases outliers\n",
      "Correction manuelle de la bsid 9949\n",
      "il reste 0 base avec lat >60\n"
     ]
    }
   ],
   "source": [
    "X_test= Correct_Bases (df_mess_test)\n",
    "X_test[X_test.bs_lat>64].shape[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On créer la liste des coordonnées de toutes les bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crééer une matrice contenant les coordonnées des bases\n",
    "base_coord = pd.concat([X_train,X_test]).drop_duplicates(subset='bsid')[['bsid','bs_lat','bs_lng']].set_index('bsid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On créer une feature distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messid</th>\n",
       "      <th>bsid</th>\n",
       "      <th>did</th>\n",
       "      <th>nseq</th>\n",
       "      <th>rssi</th>\n",
       "      <th>time_ux</th>\n",
       "      <th>bs_lat</th>\n",
       "      <th>bs_lng</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573bf1d9864fce1a9af8c5c9</td>\n",
       "      <td>2841</td>\n",
       "      <td>473335.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-121.5</td>\n",
       "      <td>1.463546e+12</td>\n",
       "      <td>39.617794</td>\n",
       "      <td>-104.954917</td>\n",
       "      <td>1.270478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     messid  bsid       did  nseq   rssi       time_ux  \\\n",
       "0  573bf1d9864fce1a9af8c5c9  2841  473335.0   0.5 -121.5  1.463546e+12   \n",
       "\n",
       "      bs_lat      bs_lng      dist  \n",
       "0  39.617794 -104.954917  1.270478  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_coord = (pos_train.set_index(keys=df_mess_train.messid.values).reset_index()).groupby('index').mean()\n",
    "X_train['dist']=0\n",
    "for i in X_train.index:\n",
    "    bs_Coord = (X_train.iloc[i].bs_lat,X_train.iloc[i].bs_lng)\n",
    "    msg_Coord = (msg_coord.loc[X_train.iloc[i].messid].lat,msg_coord.loc[X_train.iloc[i].messid].lng)\n",
    "    X_train.loc[i,'dist']=vincenty(bs_Coord,msg_Coord)\n",
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La fct feat matrice propre a notre cas où l'on fait apparaitre le Rssi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_mat_const(df, listOfBs):\n",
    "    \"\"\"On a rajouté une colonne contenant le nombre de détection par msg\n",
    "    cela servira à identifié la pondération de la prédiction\n",
    "    \"\"\"\n",
    "    df_group = df.groupby(\"messid\", as_index=False)\n",
    "    nb_mess = len(df.messid.unique())\n",
    "    df_feat = pd.DataFrame(np.zeros((nb_mess, len(listOfBs))), columns=listOfBs, index=df.messid.unique())\n",
    "    id_list = [0] * nb_mess\n",
    "\n",
    "    for i, (key, elmt) in enumerate(df_group):\n",
    "        df_feat.loc[key,elmt.bsid]= elmt.rssi.values #ici on met le rssi au lieu des 1 \n",
    "        id_list[i] = key\n",
    "        \n",
    "    \"\"\"Rajout des BaryCentres\"\"\"\n",
    "            \n",
    "    a =df.rssi.values\n",
    "    df['rssi_reshape'] = (10**(a/10))\n",
    "    df['bs_lat_pond'] = df.bs_lat * df.rssi_reshape\n",
    "    df['bs_lng_pond'] = df.bs_lng * df.rssi_reshape\n",
    "    BCW_lat = df.groupby('messid').bs_lat_pond.sum()/df.groupby('messid').rssi_reshape.sum()\n",
    "    BCW_lat.name='BCW_lat'\n",
    "    BCW_lng = df.groupby('messid').bs_lng_pond.sum()/df.groupby('messid').rssi_reshape.sum()\n",
    "    BCW_lng.name='BCW_lng'\n",
    "\n",
    "    #Pour le barycentre ajout min , max + mean \n",
    "\n",
    "    BC_lat = df.groupby('messid').agg(['mean', 'min', 'max'])[['bs_lat']]\n",
    "    BC_lat.columns = BC_lat.columns.droplevel()\n",
    "\n",
    "    BC_lng = df.groupby('messid').agg(['mean', 'min', 'max'])[['bs_lng']]\n",
    "    BC_lng.columns = BC_lng.columns.droplevel()\n",
    "\n",
    "    dev_lat =df.groupby(['did','messid']).agg(['mean', 'min', 'max'])[['bs_lat']].reset_index()\n",
    "    dev_lat.columns = dev_lat.columns.droplevel()\n",
    "    dev_lat.columns= ['did','messid','bs_l_did_mean', 'bs_l_did_min', 'bs_l_did_max']\n",
    "    dev_lat=dev_lat.drop('did',axis=1)\n",
    "\n",
    "    dev_lng =df.groupby(['did','messid']).agg(['mean', 'min', 'max'])[['bs_lng']].reset_index()\n",
    "    dev_lng.columns = dev_lng.columns.droplevel()\n",
    "    dev_lng.columns= ['did','messid','bs_L_did_mean', 'bs_L_did_min', 'bs_L_did_max']\n",
    "    dev_lng=dev_lng.drop('did',axis=1)\n",
    "\n",
    "    #On fait apparaitre une colonne contenant le messid pour la jointure\n",
    "\n",
    "    df_feat = df_feat.reset_index()\n",
    "    df_feat.rename(columns={'index':'messid'}, inplace=True)\n",
    "\n",
    "    df_feat=df_feat.join(BCW_lat, on ='messid',how='left')\n",
    "    df_feat=df_feat.join(BCW_lng, on ='messid',how='left')\n",
    "\n",
    "    df_feat= pd.merge(df_feat,BC_lat,on='messid')\n",
    "    df_feat= pd.merge(df_feat,BC_lng,on='messid')\n",
    "\n",
    "    df_feat= pd.merge(df_feat,dev_lat,on='messid')\n",
    "    df_feat= pd.merge(df_feat,dev_lng,on='messid')\n",
    "\n",
    "    #On remet le messid dans l'index\n",
    "    df_feat.set_index('messid',inplace=True)\n",
    "    \n",
    "    return df_feat, id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6068, 3), (6068, 273))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat, id_list=feat_mat_const(X_train, listOfBs)\n",
    "\n",
    "y_full = ground_truth_const(X_train, pos_train, id_list)\n",
    "y_full.shape,df_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "\"\"\"Cette celluel tourne pendant 2h !!!!!\"\"\"\n",
    "\"\"\"Le résultat est stocké en pickle voir plus bas\"\"\"\n",
    "\n",
    "\n",
    "#Code produit ensemble donc tu peux copier bêtement\n",
    "Models={}\n",
    "df_temp = df_feat[df_feat.columns[:-14]] #Ici on récupère la matrice df_feat sans columns supplémentaire\n",
    "#Pour chaque base\n",
    "for idx,base in enumerate(df_temp.columns):\n",
    "    print(f\"Base : {base}\")\n",
    "    \n",
    "    #Prod de la sous matrice df_feat (lié à la base)\n",
    "    df_feat_reduce=df_temp[df_temp[base]!=0]\n",
    "    print(f\"Nb message : {df_feat_reduce.shape[0]}\")\n",
    "    \n",
    "    #On ne produit pas de modèle pour les bases non vu dans le train\n",
    "    if df_feat_reduce.shape[0] :\n",
    "        y=[];X=[]\n",
    "        #On parcours tous les messages identifiés à une base\n",
    "        for i,k in enumerate(df_feat_reduce.index):\n",
    "            for j in df_temp.columns: #Je parcours toutes les bases et construit la matrice 259x259\n",
    "                #print(\"tip\")\n",
    "                X.append(abs(df_temp.loc[k,j]-df_temp.loc[k,df_temp.columns].values))\n",
    "                y.append(vincenty(base_coord.loc[j],msg_coord.loc[k]))\n",
    "                #print(\"top\")\n",
    "        y=np.array(y)\n",
    "        X=np.array(X)\n",
    "        #On produit un modèle pour la base en question on note également l'indice de la base \n",
    "        model = xgb.XGBRegressor().fit(X,y);\n",
    "        Models[base] = [idx,model]\n",
    "        \n",
    "        \"\"\"ce bout de code ne sert QUE a vérifier si la méthode est bonne mais n'est pas nécessaire\"\"\"\n",
    "\n",
    "        y_pred= Models[base][1].predict(X)\n",
    "        #Calcul de le MAE\n",
    "        sol=[]\n",
    "        for j in range(y_pred.shape[0]//size):\n",
    "            sol.append(y_pred[j*size:(j+1)*size][Models[base][0]])\n",
    "        a =np.array(sol)\n",
    "        b = X_train[X_train.bsid == base].dist.values \n",
    "        \n",
    "        print(f\"MAE de la base : {base} : {(np.abs(a-b)).mean()}\")\n",
    "\n",
    "    else :\n",
    "        print(f\"Base {base} en échec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"NE PAS RUNNER\"\"\"\n",
    "with open (f\"Models.pkl\",\"wb\") as fp :\n",
    "    pickle.dump(Models, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Runner cette cellule pour charger les Models\"\"\"\n",
    "with open (f\"Models.pkl\",\"rb\") as fp :\n",
    "    Models = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction sur le Train pour qualifier la solution et le fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=X_train\n",
    "df_feat, id_list=feat_mat_const(df, listOfBs)\n",
    "df_temp = df_feat[df_feat.columns[:-14]]\n",
    "df_group = df.groupby(\"messid\", as_index=False)\n",
    "nb_mess = len(df.messid.unique())\n",
    "df_feat_new = pd.DataFrame(np.zeros((nb_mess, len(listOfBs))), columns=listOfBs, index=df.messid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "for idx,base in enumerate(df_temp.columns):\n",
    "    print(f\"Base : {base}\")\n",
    "    #Prod de la sous matrice df_feat (lié à la base)\n",
    "    df_feat_reduce=df_temp[df_temp[base]!=0]\n",
    "    print(f\"Nb message : {df_feat_reduce.shape[0]}\")\n",
    "    if df_feat_reduce.shape[0]:\n",
    "        if Models.get(base,False) :\n",
    "            X=[]\n",
    "            #On parcours tous les messages identifié à une base\n",
    "            for i,k in enumerate(df_feat_reduce.index):\n",
    "                for j in df_temp.columns: #Je parcours toutes les bases et construit la matrice 259x259\n",
    "                    X.append(abs(df_temp.loc[k,j]-df_temp.loc[k,df_temp.columns]).values)\n",
    "            X=np.array(X)\n",
    "            y= Models[base][1].predict(X)\n",
    "            sol=[]\n",
    "            for j in range(y.shape[0]//size):\n",
    "                sol.append(y[j*size:(j+1)*size][Models[base][0]])\n",
    "            df_feat_new.loc[df_feat_reduce.index.values,base]=np.array(sol)\n",
    "        else:\n",
    "            print(f\"Base non modélisée {base}\")\n",
    "            \"\"\"Ici on pourrait prévoire un amélioration qui une fois le message prédit on construit le modèle\"\"\"\n",
    "    else :\n",
    "        print(f\"Base sans message {base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Je rajoute le calcul des barycente que l'on trouve dans le df_feat\n",
    "df_feat_new_TRAIN = pd.merge(df_feat_new,df_feat[df_feat.columns[-14:]],right_index=True,left_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"NE PAS RUNNER\"\"\"\n",
    "with open (f\"df_feat_new_TRAIN.pkl\",\"wb\") as fp :\n",
    "    pickle.dump(df_feat_new_TRAIN, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Runner cette cellule pour charger la df Feat du X_train\"\"\"\n",
    "with open (f\"df_feat_new_TRAIN.pkl\",\"rb\") as fp :\n",
    "    df_feat_new_TRAIN = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualification avec les hypers paramètres trouvés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = pd.read_csv(\"best_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8549834"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = RandomForestRegressor(**get_hyperparameter('RandomForestRegressor', 'lng'))\n",
    "r2 = GradientBoostingRegressor(**get_hyperparameter('GradientBoostingRegressor', 'lng'))\n",
    "r3 = ExtraTreeRegressor(**get_hyperparameter('ExtraTreeRegressor', 'lng'))\n",
    "r4 = xgb.XGBRegressor(**get_hyperparameter('XGBRegressor', 'lng'))\n",
    "r5 = BaggingRegressor(**get_hyperparameter('BaggingRegressor', 'lng'))\n",
    "Vr_lng = VotingRegressor(estimators=[('Et',r1),('Rf',r2),('Gb',r3),('Xg',r4),('Xdg',r5)])\n",
    "\n",
    "\n",
    "r1 = RandomForestRegressor(**get_hyperparameter('RandomForestRegressor', 'lat'))\n",
    "r2 = GradientBoostingRegressor(**get_hyperparameter('GradientBoostingRegressor', 'lat'))\n",
    "r3 = ExtraTreeRegressor(**get_hyperparameter('ExtraTreeRegressor', 'lat'))\n",
    "r4 = xgb.XGBRegressor(**get_hyperparameter('XGBRegressor', 'lat'))\n",
    "r5 = BaggingRegressor(**get_hyperparameter('BaggingRegressor', 'lat'))\n",
    "Vr_lat = VotingRegressor(estimators=[('Et',r1),('Rf',r2),('Gb',r3),('Xg',r4),('Xdg',r5)])\n",
    "\n",
    "y_pred_lng = cross_val_predict(Vr_lng, df_feat_new_TRAIN, y_full.lng, cv=3)\n",
    "y_pred_lat = cross_val_predict(Vr_lat, df_feat_new_TRAIN, y_full.lat, cv=3)\n",
    "\n",
    "err_vec = Eval_geoloc(y_full.lat , y_full.lng, y_pred_lat, y_pred_lng)\n",
    "np.percentile(err_vec, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction du Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=X_test\n",
    "df_feat, id_list=feat_mat_const(df, listOfBs)\n",
    "df_temp = df_feat[df_feat.columns[:-14]]\n",
    "df_group = df.groupby(\"messid\", as_index=False)\n",
    "nb_mess = len(df.messid.unique())\n",
    "df_feat_new = pd.DataFrame(np.zeros((nb_mess, len(listOfBs))), columns=listOfBs, index=df.messid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "for idx,base in enumerate(df_temp.columns):\n",
    "    print(f\"Base : {base}\")\n",
    "    #Prod de la sous matrice df_feat (lié à la base)\n",
    "    df_feat_reduce=df_temp[df_temp[base]!=0]\n",
    "    print(f\"Nb message : {df_feat_reduce.shape[0]}\")\n",
    "    if df_feat_reduce.shape[0]:\n",
    "        if Models.get(base,False) :\n",
    "            X=[]\n",
    "            #On parcours tous les messages identifié à une base\n",
    "            for i,k in enumerate(df_feat_reduce.index):\n",
    "                for j in df_temp.columns: #Je parcours toutes les bases et construit la matrice 259x259\n",
    "                    X.append(abs(df_temp.loc[k,j]-df_temp.loc[k,df_temp.columns]).values)\n",
    "            X=np.array(X)\n",
    "            y= Models[base][1].predict(X)\n",
    "            sol=[]\n",
    "            for j in range(y.shape[0]//size):\n",
    "                sol.append(y[j*size:(j+1)*size][Models[base][0]])\n",
    "            df_feat_new.loc[df_feat_reduce.index.values,base]=np.array(sol)\n",
    "        else:\n",
    "            print(f\"Base non modélisée {base}\")\n",
    "            \"\"\"Ici on pourrait prévoire un amélioration qui une fois le message prédit on construit le modèle\"\"\"\n",
    "    else :\n",
    "        print(f\"Base sans message {base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_feat_new_TEST = pd.merge(df_feat_new,df_feat[df_feat.columns[-14:]],right_index=True,left_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"NE PAS RUNNER\"\"\"\n",
    "with open (f\"df_feat_new_TEST.pkl\",\"wb\") as fp :\n",
    "    pickle.dump(df_feat_new_TEST, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Runner cette cellule pour charger la df Feat du X_test\"\"\"\n",
    "with open (f\"df_feat_new_TEST.pkl\",\"rb\") as fp :\n",
    "    df_feat_new_TEST = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = RandomForestRegressor(**get_hyperparameter('RandomForestRegressor', 'lng'))\n",
    "r2 = GradientBoostingRegressor(**get_hyperparameter('GradientBoostingRegressor', 'lng'))\n",
    "r3 = ExtraTreeRegressor(**get_hyperparameter('ExtraTreeRegressor', 'lng'))\n",
    "r4 = xgb.XGBRegressor(**get_hyperparameter('XGBRegressor', 'lng'))\n",
    "r5 = BaggingRegressor(**get_hyperparameter('BaggingRegressor', 'lng'))\n",
    "Vr_lng = VotingRegressor(estimators=[('Et',r1),('Rf',r2),('Gb',r3),('Xg',r4),('Xdg',r5)])\n",
    "\n",
    "\n",
    "r1 = RandomForestRegressor(**get_hyperparameter('RandomForestRegressor', 'lat'))\n",
    "r2 = GradientBoostingRegressor(**get_hyperparameter('GradientBoostingRegressor', 'lat'))\n",
    "r3 = ExtraTreeRegressor(**get_hyperparameter('ExtraTreeRegressor', 'lat'))\n",
    "r4 = xgb.XGBRegressor(**get_hyperparameter('XGBRegressor', 'lat'))\n",
    "r5 = BaggingRegressor(**get_hyperparameter('BaggingRegressor', 'lat'))\n",
    "Vr_lat = VotingRegressor(estimators=[('Et',r1),('Rf',r2),('Gb',r3),('Xg',r4),('Xdg',r5)])\n",
    "\n",
    "Vr_lng.fit(df_feat_new_TRAIN, y_full.lng)\n",
    "Vr_lat.fit(df_feat_new_TRAIN, y_full.lat)\n",
    "\n",
    "y_pred_lng = Vr_lng.predict(df_feat_new_TEST)\n",
    "y_pred_lat = Vr_lat.predict(df_feat_new_TEST)\n",
    "\n",
    "#Il faut produire le fichier solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-105.11921928, -105.08057484, -105.0147477 , ..., -105.03055694,\n",
       "       -105.02294792, -105.02297024])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.72010534, 39.77769262, 39.68975325, ..., 39.68913253,\n",
       "       39.67764977, 39.68792618])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = pd.DataFrame({'lat':y_pred_lat,'lng':y_pred_lng,'messid':df_feat_new_TEST.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.to_csv(\"calligaro.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"pred_pos_test_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       39.772912\n",
       "1       39.774800\n",
       "2       39.678750\n",
       "3       39.773684\n",
       "4       39.678750\n",
       "          ...    \n",
       "5289    39.745662\n",
       "5290    39.778171\n",
       "5291    39.692797\n",
       "5292    39.741485\n",
       "5293    39.699054\n",
       "Name: lat, Length: 5294, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.072840800000007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_vec = Eval_geoloc(test.lat , test.lng, y_pred_lat, y_pred_lng)\n",
    "np.percentile(err_vec, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] Le module spécifié est introuvable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-466c03e4bd72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mipyleaflet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasemaps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmsg_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_pred_lat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lng'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_pred_lng\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_feat_new_TEST\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbarycentre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmsg_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\site-packages\\ipyleaflet\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mleaflet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbasemaps\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasemaps\u001b[0m   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\site-packages\\ipyleaflet\\leaflet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbranca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColorMap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwkt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEXTENSION_VERSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\site-packages\\shapely\\geometry\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \"\"\"\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCAP_STYLE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJOIN_STYLE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mgeo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masShape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpoint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masPoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\site-packages\\shapely\\geometry\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffinity\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoords\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCoordinateSequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWKBReadingError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWKTReadingError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWKBWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWKTWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\site-packages\\shapely\\coords.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mctypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbyref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_double\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_uint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlgeos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mValidating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\site-packages\\shapely\\geos.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CONDA_PREFIX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;31m# conda package.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0m_lgeos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Library'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'geos_c.dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Anaconda\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] Le module spécifié est introuvable"
     ]
    }
   ],
   "source": [
    "from ipyleaflet import Map, basemaps\n",
    "msg_test = pd.DataFrame({'lat':y_pred_lat,'lng':y_pred_lng},index=df_feat_new_TEST.index)\n",
    "\n",
    "barycentre = ((msg_test.lat.max()+msg_test.lat.min())/2,(msg_test.lng.min()+msg_test.lng.max())/2)\n",
    "\n",
    "m = Map(center=barycentre, zoom=3, basemap = basemaps.OpenStreetMap.Mapnik)\n",
    "\n",
    "message = Give_Marker_Cluster(msg_test)\n",
    "\n",
    "m.add_layer(message)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
